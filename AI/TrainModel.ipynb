{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b9d174c",
   "metadata": {},
   "source": [
    "# Doučenje modela google/vit-base-patch16-224 za prepoznavanje in ocenjevanje slik hrane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4641f027",
   "metadata": {},
   "source": [
    "Učenje poteka po vzorcu na povezavi: https://huggingface.co/learn/cookbook/fine_tuning_vit_custom_dataset#fine-tuning-the-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f61cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "my_token = \"#####################################\"\n",
    "login(token=my_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3326bd18",
   "metadata": {},
   "source": [
    "### Priprava podatkov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c65262",
   "metadata": {},
   "source": [
    "V tem bloku kode se najprej naloži slikovni nabor podatkov iz mape \"./data/images\" s pomočjo Hugging Face funkcije load_dataset, pri čemer se stolpec \"image\" eksplicitno nastavi, da ne dešifrira slik (tako da vsak primer vsebuje le pot do slike). Nato se iz CSV datoteke \"./data/metadata.csv\" preberejo metapodatki (ocene) za posamezne slike in se zgradi slovar (score_dict), kjer so ključi imena slik, vrednosti pa ocene za kategorije \"zdravo\", \"raznoliko\", \"domace\" in \"jehrana\". Funkcija add_scores_from_csv nato za vsak primer dobi ime slike iz poti, s tem pridobi ustrezne ocene iz slovarja (če slike ne najde, nastavi ocene na 0) in jih doda v primer. Na koncu se podatki razdelijo na treniranje, validacijo in testiranje, pri čemer se na vsak sklop uporabi ta funkcija, da se vsakemu primeru združijo ustrezni metapodatki – to je potrebno, ker model potrebuje te ročno zapisane ocene za nadaljnjo obdelavo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04e5ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Image, Features, ClassLabel\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1 ustvarimo slovar, ki pove HF: \"Ne dekodiraj 'image'.\"\n",
    "\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"./data/images\")  # By default decodes, but we'll override\n",
    "dataset = dataset.cast_column(\"image\", Image(decode=False))\n",
    "\n",
    "\n",
    "# 2) Ustvarimo slovar iz CSV datoteke, ki vsebuje ocene\n",
    "df_meta = pd.read_csv(\"./data/metadata.csv\")\n",
    "score_dict = {}\n",
    "for idx, row in df_meta.iterrows():\n",
    "    fn = row[\"file_name\"]\n",
    "    score_dict[fn] = {\n",
    "        \"zdravo\":     row[\"zdravo\"],\n",
    "        \"raznoliko\":  row[\"raznoliko\"],\n",
    "        \"domace\":     row[\"domace\"],\n",
    "        \"jehrana\":    row[\"jehrana\"]\n",
    "    }\n",
    "\n",
    "# 3) Naredimo funkcijo, ki uporablja 'example[\"image\"][\"path\"]'\n",
    "def add_scores_from_csv(example):\n",
    "    # Zdaj lahko enostavno dostopamo do poti\n",
    "    path = example[\"image\"][\"path\"]\n",
    "    base_name = os.path.basename(path)            # e.g. \"zdravaHrana1.jpg\"\n",
    "    file_stem = os.path.splitext(base_name)[0]    # e.g. \"zdravaHrana1\"\n",
    "\n",
    "    if file_stem in score_dict:\n",
    "        example[\"zdravo\"]     = score_dict[file_stem][\"zdravo\"]\n",
    "        example[\"raznoliko\"]  = score_dict[file_stem][\"raznoliko\"]\n",
    "        example[\"domace\"]     = score_dict[file_stem][\"domace\"]\n",
    "        example[\"jehrana\"]    = score_dict[file_stem][\"jehrana\"]\n",
    "    else:\n",
    "        example[\"zdravo\"]     = 0\n",
    "        example[\"raznoliko\"]  = 0\n",
    "        example[\"domace\"]     = 0\n",
    "        example[\"jehrana\"]    = 0\n",
    "\n",
    "    return example\n",
    "\n",
    "# 4) Razdelimo podatke na train/validation/test \n",
    "split_1 = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "split_2 = split_1[\"train\"].train_test_split(test_size=0.125, seed=42)  # 10% of remaining 80% is validation\n",
    "\n",
    "train_ds = DatasetDict({\n",
    "    \"train\":      split_2[\"train\"].map(add_scores_from_csv),\n",
    "    \"validation\": split_2[\"test\"].map(add_scores_from_csv),\n",
    "    \"test\":       split_1[\"test\"].map(add_scores_from_csv)\n",
    "})\n",
    "\n",
    "print(\"Train:\", len(train_ds[\"train\"]))\n",
    "print(\"Validation:\", len(train_ds[\"validation\"]))\n",
    "print(\"Test:\", len(train_ds[\"test\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ee825",
   "metadata": {},
   "source": [
    "### Preslikava oznak\n",
    "Oznakam priredimo ID, ki se potem ujemajo z imenom. Uporabno za treniranje in ocenjevanje modela.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2930dbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"zdravo\", \"raznoliko\", \"domace\", \"jehrana\"]\n",
    "label2id = {label: idx for idx, label in enumerate(label_names)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_multi_hot_label(example):\n",
    "    # Preberemo stolpce (privzeto 0, če jih ni)\n",
    "    score_zdravo    = example.get(\"zdravo\", 0)\n",
    "    score_raznoliko = example.get(\"raznoliko\", 0)\n",
    "    score_domace    = example.get(\"domace\", 0)\n",
    "    score_jehrana   = example.get(\"jehrana\", 0)\n",
    "    \n",
    "    # Shranimo kot 4-elementni seznam \n",
    "    # (lahko je float: 0.0 ali 1.0 - odvisno od tvojih podatkov)\n",
    "    example[\"labels\"] = [score_zdravo, score_raznoliko, score_domace, score_jehrana]\n",
    "    \n",
    "    return example\n",
    "\n",
    "# Apply the function to every split in your dataset\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    train_ds[split] = train_ds[split].map(create_multi_hot_label)\n",
    "\n",
    "# Verify that the \"label\" field has been added\n",
    "print(train_ds[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032f3a7c",
   "metadata": {},
   "source": [
    "### Procesiranje slik\n",
    "\n",
    "\n",
    "Uporabimo VitImageProcessor, da poenotimo vhod  velikosti slik in jih normaliziramo za že treniran model.\n",
    "Definiramo tudi različne transformacije za treniranje, validacijo in testiranje modela, da ga lahko izboljšamo z \"torchvision\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b34a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTImageProcessor\n",
    "\n",
    "model_name = \"google/vit-large-patch16-224\"\n",
    "processor = ViTImageProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a088d89",
   "metadata": {},
   "source": [
    "V tem delu se definirajo različne transformacije za trening, validacijo in testiranje: za trening se uporablja naključno prilagajanje velikosti in horizontalno preklapljanje, medtem ko se za validacijo/testiranje slike najprej prilagodijo z Resize in CenterCrop. Nato se slike pretvorijo v tensore in normalizirajo z mean in std vrednostmi, pridobljenimi iz ViTImageProcessorja, kar zagotovi enotno predobdelavo za model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1a039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    ToTensor,\n",
    "    Resize,\n",
    ")\n",
    "\n",
    "image_mean, image_std = processor.image_mean, processor.image_std\n",
    "size = processor.size[\"height\"]\n",
    "\n",
    "normalize = Normalize(mean=image_mean, std=image_std)\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        RandomResizedCrop(size),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        Resize(size),\n",
    "        CenterCrop(size),\n",
    "        ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        Resize(size),\n",
    "        CenterCrop(size),\n",
    "        ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba7fd5",
   "metadata": {},
   "source": [
    "#### Ustvarjanje transform funkcij\n",
    "\n",
    "Implementiramo funkcije za transformacijo podatkov za vse tri datasete. \n",
    "Slike spremenimo v pravilen format in velikost za ViT model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2688ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_train_transforms(examples):\n",
    "    examples[\"pixel_values\"] = [train_transforms(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
    "    return examples\n",
    "\n",
    "\n",
    "def apply_val_transforms(examples):\n",
    "    examples[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
    "    return examples\n",
    "\n",
    "\n",
    "def apply_test_transforms(examples):\n",
    "    examples[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd64efb",
   "metadata": {},
   "source": [
    "Transformacije uporabimo nad vsakim delom podatkov.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0ba5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[\"train\"].set_transform(apply_train_transforms)\n",
    "train_ds[\"validation\"].set_transform(apply_val_transforms)\n",
    "train_ds[\"test\"].set_transform(apply_test_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5135b",
   "metadata": {},
   "source": [
    "#### Nalaganje podatkov\n",
    "\n",
    "Naredimo lastno collate funkcijo, ki ustvari pravilne serije slik in oznak.\n",
    "Ustvarimo Dataloader za učinkovito nalaganje in serializacijo med treniranjem modela.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0722137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    # Vsak example[\"labels\"] je zdaj seznam dolžine 4\n",
    "    labels = torch.tensor([example[\"labels\"] for example in examples], dtype=torch.float)\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e9dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dl = DataLoader(train_ds[\"train\"], collate_fn=collate_fn, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ab9457",
   "metadata": {},
   "source": [
    "#### Fine-tuning the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b9160",
   "metadata": {},
   "source": [
    "Naložimo model ViTForImageClassification iz predtreniranega modela z naslednjimi nastavitvami: nastavljen je na 4 oznake, uporabljamo multi-label pristop, preslikave med imeni in id-ji oznak so določene s parametri id2label in label2id, ter parameter ignore_mismatched_sizes=True omogoča nalaganje modela, četudi se dimenzije tehtnic ne ujemajo popolnoma.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64971c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=4,\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33b629",
   "metadata": {},
   "source": [
    "Prijavimo se v storitev Weights & Biases (wandb) z uporabo danega ključa, s čimer omogoči spremljanje eksperimentov, treniranja in vizualizacijo metrik med treniranjem modela.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5099b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"########################################\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d938c0",
   "metadata": {},
   "source": [
    "S pomočjo funkcije cast_column iz knjižnice datasets se stolpec \"image\" v trenirnem, validacijskem in testnem naboru ponovno pretvori – tokrat se slike dešifrirajo (decode=True), tako da so vsaka slika predstavljena kot pravi PIL objekt, ki se lahko uporabi pri nadaljnji obdelavi (npr. transformacijah in inferenci)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b22e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Image\n",
    "\n",
    "train_ds[\"train\"] = train_ds[\"train\"].cast_column(\"image\", Image(decode=True))\n",
    "train_ds[\"validation\"] = train_ds[\"validation\"].cast_column(\"image\", Image(decode=True))\n",
    "train_ds[\"test\"] = train_ds[\"test\"].cast_column(\"image\", Image(decode=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb0416c",
   "metadata": {},
   "source": [
    "Preverimo celovitost in strukturo trenirnega nabora podatkov s tem, da izpiše število primerov v trenirnem naboru, prikaže en primer za vizualno potrditev pravilne strukture, izpiše nastavitve modela (da ima model pričakovano število izhodnih oznak) ter preveri, ali funkcija za združevanje (collate_fn) pravilno združuje podatke v serije, kar potrdi z izpisom oblik vhodnih slikovnih tenzorjev in oznak.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d12184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 1. Preveri če podatki obstajajo\n",
    "print(\"Train set size:\", len(train_ds[\"train\"]))\n",
    "\n",
    "# 2. Preveri en primer\n",
    "print(train_ds[\"train\"][0])\n",
    "\n",
    "# 3. Preveri ali se število glav modela ujema s številom oznak\n",
    "print(model.config.num_labels)\n",
    "\n",
    "# 4. Preveri ali collator vrne pravilne oblike\n",
    "batch = [train_ds[\"train\"][i] for i in range(4)]\n",
    "collated = collate_fn(batch)\n",
    "print(collated[\"pixel_values\"].shape, collated[\"labels\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce69036",
   "metadata": {},
   "source": [
    "Naložimo predtreniran model ViTForImageClassification in ga ponovno nastavimo za regresijo, kar pomeni, da se spremeni tip problema (problem_type=\"regression\") in s tem se interna funkcija zgube, ki se uporablja, spremeni (npr. na MSE – srednja kvadratna napaka). Pri tem se model nastavi s štirimi izhodnimi oznakami, kjer se preslikave med imeni in numeričnimi identifikatorji zagotavljajo z id2label in label2id, parameter ignore_mismatched_sizes pa omogoča nalaganje modela tudi v primeru neujemanja dimenzij. Takšna konfiguracija je primerna za regresijske naloge, kjer so vrednosti ne le binarne, temveč zvezne ocene."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027e202",
   "metadata": {},
   "source": [
    "Nato se definirajo parametri za treniranje s pomočjo TrainingArguments, kjer se nastavi izhodna mapa, velikosti batch-ev, število epoch-ov, pogostost logiranja in shranjevanja ter druge možnosti. Nato se ustvari Trainer, ki model poveže z naborom trenirnih in validacijskih podatkov, uporablja definiran data collator (ki združuje podatke v batch-e) in processor kot tokenizer. Na koncu se s klicema trainer.train() in trainer.evaluate() sproži proces treniranja in evalvacije modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e98c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=4,\n",
    "    problem_type=\"regression\",  \n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    output_dir=\"./vit-checkpoints\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=4,\n",
    "    logging_steps=10,\n",
    "    save_steps=50,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=train_ds[\"train\"],\n",
    "    eval_dataset=train_ds[\"validation\"],\n",
    "    data_collator=collate_fn,\n",
    "    tokenizer=processor,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
